#!/usr/bin/env python3
"""
KKæ–‡æ¡£å¤„ç†å·¥å…· - ä¸»ç¨‹åºå…¥å£
"""

import sys
import os
import argparse
import re
import signal
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å°è¯•å¯¼å…¥document_processor
try:
    from document_processor import DocumentProcessor
    print("âœ… document_processor å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âš ï¸  document_processor å¯¼å…¥å¤±è´¥ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    DocumentProcessor = None

# é»˜è®¤ç¤ºä¾‹æ–‡æœ¬
DEFAULT_TEXT = """This is a default example document. Used when no input text is provided.

## Chapter Title
- Item 1: Example content
- Item 2: More examples

Main paragraph content will be displayed here. This tool is used for document conversion and summary extraction.
"""

def read_file_content(filename):
    """è¯»å–æ–‡ä»¶å†…å®¹"""
    try:
        filepath = Path(filename)
        if not filepath.exists():
            return None
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            return content if content else None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        return None

def get_input_text(args):
    """
    è·å–è¾“å…¥æ–‡æœ¬ï¼ŒæŒ‰ä¼˜å…ˆçº§å¤„ç†ï¼š
    1. --text å‚æ•°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    2. --file å‚æ•°
    3. text.txt æ–‡ä»¶ï¼ˆåå¤‡ï¼‰
    4. é»˜è®¤ç¤ºä¾‹æ–‡æœ¬ï¼ˆæœ€åï¼‰
    """
    # 1. å‘½ä»¤è¡Œç›´æ¥è¾“å…¥æ–‡æœ¬
    if args.text:
        print(f"ğŸ’¬ ä½¿ç”¨å‘½ä»¤è¡Œæ–‡æœ¬è¾“å…¥")
        return args.text
    
    # 2. æŒ‡å®šæ–‡ä»¶
    if args.file:
        content = read_file_content(args.file)
        if content:
            print(f"ğŸ“ ä»æŒ‡å®šæ–‡ä»¶è¯»å–: {args.file}")
            return content
        else:
            print(f"âš ï¸ æŒ‡å®šæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º: {args.file}")
    
    # 3. text.txt æ–‡ä»¶ï¼ˆåå¤‡ï¼‰
    content = read_file_content("text.txt")
    if content:
        print(f"ğŸ“ ä»text.txtè¯»å–")
        return content
    
    # 4. é»˜è®¤ç¤ºä¾‹æ–‡æœ¬
    print("âš ï¸ ä½¿ç”¨é»˜è®¤ç¤ºä¾‹æ–‡æœ¬")
    return DEFAULT_TEXT

def _split_paragraphs(content: str) -> list:
    """
    å°†å†…å®¹åˆ†å‰²æˆè‡ªç„¶æ®µæ•°ç»„
    """
    paragraphs = []
    current_paragraph = []
    
    lines = content.split('\n')
    
    for line in lines:
        stripped_line = line.strip()
        
        if not stripped_line:  # ç©ºè¡Œï¼Œè¡¨ç¤ºæ®µè½åˆ†éš”
            if current_paragraph:  # å½“å‰æ®µè½æœ‰å†…å®¹
                paragraph_text = '\n'.join(current_paragraph)
                paragraphs.append(paragraph_text)
                current_paragraph = []
        else:
            current_paragraph.append(line)
    
    if current_paragraph:
        paragraph_text = '\n'.join(current_paragraph)
        paragraphs.append(paragraph_text)
    
    if not paragraphs and content.strip():
        paragraphs = [content.strip()]
    
    return paragraphs

def _generate_heading(paragraph: str, max_words: int = 4) -> str:
    """
    ä¸ºæ®µè½ç”ŸæˆäºŒçº§æ ‡é¢˜
    """
    if hasattr(_generate_heading, '_in_progress'):
        return "Content Summary"
    
    _generate_heading._in_progress = True
    
    try:
        if DocumentProcessor is not None:
            if not hasattr(_generate_heading, '_processor'):
                _generate_heading._processor = DocumentProcessor()
            
            processor = _generate_heading._processor
            
            def timeout_handler(signum, frame):
                raise TimeoutError("æ ‡é¢˜ç”Ÿæˆè¶…æ—¶")
            
            original_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(10)
            
            try:
                # ä½¿ç”¨ generate_heading æ–¹æ³•
                heading = processor.generate_heading(paragraph, max_words=max_words)
                signal.alarm(0)
                
                if heading and heading.strip():
                    heading = heading.strip()
                    heading = re.sub(r'[.!?ã€‚ï¼ï¼Ÿ]+$', '', heading)
                    return heading
                    
            except TimeoutError:
                print("âš ï¸ æ ‡é¢˜ç”Ÿæˆè¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜")
                return "Content Summary"
            except Exception as e:
                print(f"âŒ è°ƒç”¨æ ‡é¢˜ç”ŸæˆåŠŸèƒ½å¤±è´¥: {e}")
            finally:
                signal.alarm(0)
                signal.signal(signal.SIGALRM, original_handler)
                
    except Exception as e:
        print(f"âŒ æ ‡é¢˜ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        if hasattr(_generate_heading, '_in_progress'):
            delattr(_generate_heading, '_in_progress')
    
    return "Content Summary"

def _format_heading_markdown(heading_text: str) -> str:
    """
    å°†æ ‡é¢˜æ–‡æœ¬æ ¼å¼åŒ–ä¸ºMarkdownäºŒçº§æ ‡é¢˜æ ¼å¼
    """
    cleaned_heading = heading_text.strip()
    cleaned_heading = re.sub(r'^[:\-\s]+|[:\-\s]+$', '', cleaned_heading)
    
    if not cleaned_heading:
        cleaned_heading = "Content Summary"
    
    return f"## {cleaned_heading}"

def _process_content_with_headings(content: str, max_words: int = 4) -> str:
    """
    å¤„ç†å†…å®¹ï¼Œä¸ºè‡ªç„¶æ®µæ·»åŠ äºŒçº§æ ‡é¢˜ï¼ˆä»…ç”¨äºè‹±æ–‡å†…å®¹ï¼‰
    """
    print(f"ğŸ” å¼€å§‹å¤„ç†è‹±æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
    
    try:
        paragraphs = _split_paragraphs(content)
        print(f"ğŸ“Š åˆ†å‰²å‡º {len(paragraphs)} ä¸ªè‡ªç„¶æ®µ")
        
        processed_paragraphs = []
        
        for i, paragraph in enumerate(paragraphs):
            print(f"ğŸ” æ­£åœ¨å¤„ç†æ®µè½ {i+1}/{len(paragraphs)}")
            
            try:
                cleaned_paragraph = paragraph.strip()
                if not cleaned_paragraph:
                    print(f"  æ®µè½ {i+1}: ç©ºæ®µè½ï¼Œè·³è¿‡")
                    continue
                
                print(f"  æ®µè½ {i+1} é•¿åº¦: {len(cleaned_paragraph)} å­—ç¬¦")
                    
                if len(cleaned_paragraph) > 100:
                    print(f"  æ®µè½ {i+1}: éœ€è¦ç”Ÿæˆæ ‡é¢˜")
                    heading_text = _generate_heading(cleaned_paragraph, max_words)
                    markdown_heading = _format_heading_markdown(heading_text)
                    processed_paragraphs.append(f"{markdown_heading}\n\n{cleaned_paragraph}")
                    
                    print(f"  æ®µè½ {i+1}: æ·»åŠ æ ‡é¢˜ '{heading_text}'")
                else:
                    processed_paragraphs.append(cleaned_paragraph)
                    print(f"  æ®µè½ {i+1}: ä¿ç•™åŸæ ¼å¼")
                        
            except Exception as e:
                print(f"âŒ å¤„ç†æ®µè½ {i+1} æ—¶å‡ºé”™: {e}")
                processed_paragraphs.append(paragraph.strip())
        
        print(f"âœ… æ‰€æœ‰æ®µè½å¤„ç†å®Œæˆï¼Œå…± {len(processed_paragraphs)} ä¸ªæ®µè½")
        return '\n\n'.join(processed_paragraphs)
        
    except Exception as e:
        print(f"âŒ å¤„ç†å†…å®¹æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return content

def _translate_to_chinese(content: str) -> str:
    """
    å°†æ•´ç¯‡è‹±æ–‡æ–‡æ¡£ç¿»è¯‘æˆä¸­æ–‡
    """
    if DocumentProcessor is None:
        print("âš ï¸  document_processor ä¸å¯ç”¨ï¼Œæ— æ³•ç¿»è¯‘å†…å®¹")
        return content
    
    try:
        processor = DocumentProcessor()
        print("ğŸŒ å¼€å§‹æ•´ä½“ç¿»è¯‘æ–‡æ¡£...")
        print(f"ğŸ“Š ç¿»è¯‘å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        translated = processor.translate_text(content, "è‹±æ–‡", "ä¸­æ–‡")
        
        print("âœ… æ•´ä½“ç¿»è¯‘å®Œæˆ")
        return translated
        
    except Exception as e:
        print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        return content

def _format_chinese_document(chinese_doc: str, original_title: str, cn_url: str, 
                           publish_date: str, subject: str, original_url: str) -> str:
    """
    æ ¼å¼åŒ–ç¿»è¯‘åçš„ä¸­æ–‡æ–‡æ¡£
    """
    return chinese_doc

def _generate_markdown_pair(content: str, title: str, 
                           subject: str = "é€šç”¨",
                           original_url: str = "", 
                           publish_date: str = "",
                           output_dir: str = "."):
    """
    ç”Ÿæˆä¸­è‹±æ–‡Markdownæ–‡ä»¶å¯¹
    """
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    if not publish_date:
        publish_date = datetime.now().strftime("%Y-%m-%d")
    
    def _sanitize_filename(filename: str) -> str:
        return re.sub(r'[\\/*?:"<>|]', "", filename).replace(" ", "_")
    
    en_filename = f"{_sanitize_filename(title)}.md"
    cn_filename = f"{_sanitize_filename(title)}_cn.md"
    
    en_filepath = output_path / en_filename
    cn_filepath = output_path / cn_filename
    
    en_url = f"https://github.com/Angelagoodboy/KK_Archive/blob/main/{en_filename}"
    cn_url = f"https://github.com/Angelagoodboy/KK_Archive/blob/main/{cn_filename}"
    
    # å¤„ç†è‹±æ–‡ç‰ˆ
    print("ğŸ“ æ­£åœ¨ä¸ºè‹±æ–‡å†…å®¹æ·»åŠ äºŒçº§æ ‡é¢˜...")
    processed_en_content = _process_content_with_headings(content)
    
    # ç”Ÿæˆè‹±æ–‡ç‰ˆå…ƒæ•°æ®
    en_metadata = f"""> **Publish Date**: {publish_date}  
> **Author**: Kevin Kelly  
> **Subject**: {subject}  

**Document Information**
- Original URL: {original_url if original_url else "Not provided"}
- Chinese Version: [{cn_url}]({cn_url})"""
    
    # å·²å»æ‰ "Document generated by KK Document Processor" æ ‡è®°
    en_md = f"""# {title}

{en_metadata}

{processed_en_content}
"""
    
    # ç¿»è¯‘æˆä¸­æ–‡
    print("ğŸŒ æ­£åœ¨ç¿»è¯‘å®Œæ•´çš„è‹±æ–‡Markdownæ–‡æ¡£...")
    print(f"ğŸ“Š ç¿»è¯‘å†…å®¹é•¿åº¦: {len(en_md)} å­—ç¬¦")
    
    chinese_md = _translate_to_chinese(en_md)
    cn_md = _format_chinese_document(chinese_md, title, cn_url, publish_date, subject, original_url)
    
    # å†™å…¥æ–‡ä»¶
    with open(en_filepath, 'w', encoding='utf-8') as f:
        f.write(en_md)
    
    with open(cn_filepath, 'w', encoding='utf-8') as f:
        f.write(cn_md)
    
    print(f"âœ… æ–‡ä»¶ç”Ÿæˆå®Œæˆ:")
    print(f"   â€¢ è‹±æ–‡ç‰ˆ: {en_filepath}")
    print(f"   â€¢ ä¸­æ–‡ç‰ˆ: {cn_filepath}")
    
    return str(en_filepath), str(cn_filepath)

def extract_summary(args):
    """æå–æ–‡æœ¬æ‘˜è¦"""
    if DocumentProcessor is None:
        print("âŒ document_processor ä¸å¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œæ‘˜è¦æå–")
        return
    
    text = get_input_text(args)
    
    processor = DocumentProcessor()
    
    print(f"ğŸ“ è¾“å…¥æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    if args.verbose:
        preview = text[:200] + "..." if len(text) > 200 else text
        print(f"ğŸ“‹ å†…å®¹é¢„è§ˆ: {preview}")
    
    print("ğŸ¤– æ­£åœ¨æå–æ‘˜è¦...")
    try:
        summary = processor.extract_summary(text, args.max_words)
        word_count = len(summary.split())
        
        print(f"âœ… æ‘˜è¦æå–å®Œæˆ!")
        print(f"ğŸ“Š æ‘˜è¦ ({word_count}/{args.max_words} å•è¯):")
        print(f"   {summary}")
    except Exception as e:
        print(f"âŒ æ‘˜è¦æå–å¤±è´¥: {e}")
        words = text.split()[:args.max_words]
        fallback_summary = " ".join(words)
        print(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ‘˜è¦: {fallback_summary}")

def generate_markdown_pair(args):
    """ç”Ÿæˆä¸­è‹±æ–‡Markdownæ–‡ä»¶å¯¹"""
    text = get_input_text(args)
    
    print(f"ğŸ“„ æ­£åœ¨ç”Ÿæˆæ–‡æ¡£å¯¹: {args.title}")
    print(f"ğŸ·ï¸ æ–‡æ¡£ä¸»é¢˜: {args.subject}")
    if args.output:
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    
    try:
        en_file, cn_file = _generate_markdown_pair(
            content=text,
            title=args.title,
            subject=args.subject,
            original_url=args.url,
            publish_date=args.date,
            output_dir=args.output
        )
        
        print(f"âœ… ç”Ÿæˆå®Œæˆ!")
        print(f"   â€¢ è‹±æ–‡ç‰ˆ: {en_file}")
        print(f"   â€¢ ä¸­æ–‡ç‰ˆ: {cn_file}")
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")

def setup_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="KKæ–‡æ¡£å¤„ç†å·¥å…· - æ™ºèƒ½æ–‡æ¡£è½¬æ¢å’Œæ‘˜è¦æå–",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  æ‘˜è¦æå–: python main.py summary --text "è¦æ‘˜è¦çš„æ–‡æœ¬"
  ç”Ÿæˆæ–‡æ¡£å¯¹: python main.py generate --title "æ ‡é¢˜" --subject "AI" --file input.txt --output docs/
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='é€‰æ‹©æ“ä½œå‘½ä»¤')
    
    input_group = argparse.ArgumentParser(add_help=False)
    input_group.add_argument('--text', '-t', help='ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹')
    input_group.add_argument('--file', '-f', help='ä»æ–‡ä»¶è¯»å–å†…å®¹')
    input_group.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    input_group.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼')
    
    summary_parser = subparsers.add_parser('summary', help='æå–æ–‡æœ¬æ‘˜è¦', parents=[input_group])
    summary_parser.add_argument('--max-words', '-w', type=int, default=5, help='æ‘˜è¦æœ€å¤§å•è¯æ•°')
    
    generate_parser = subparsers.add_parser('generate', help='ç”Ÿæˆä¸­è‹±æ–‡æ–‡æ¡£å¯¹', parents=[input_group])
    generate_parser.add_argument('--title', required=True, help='æ–‡æ¡£æ ‡é¢˜')
    generate_parser.add_argument('--subject', '-s', default='é€šç”¨', help='æ–‡æ¡£ä¸»é¢˜ï¼ˆå¦‚AIã€ç§‘æŠ€ç­‰ï¼‰')
    generate_parser.add_argument('--url', '-u', default='', help='åŸæ–‡URL')
    generate_parser.add_argument('--date', '-d', default='', help='å‘å¸ƒæ—¥æœŸ')
    generate_parser.add_argument('--output', '-o', default='.', help='è¾“å‡ºç›®å½•')
    
    return parser

def main():
    """ä¸»å‡½æ•°"""
    parser = setup_parser()
    
    if len(sys.argv) == 1:
        parser.print_help()
        return
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == 'summary':
            extract_summary(args)
        elif args.command == 'generate':
            generate_markdown_pair(args)
        else:
            parser.print_help()
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()